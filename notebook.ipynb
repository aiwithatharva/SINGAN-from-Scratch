{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_image(image_path, max_size=250):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    max_dim = max(image.size)\n",
    "    scale_factor = max_size / max_dim\n",
    "    new_size = (int(image.size[0] * scale_factor), int(image.size[1] * scale_factor))\n",
    "    image = image.resize(new_size, Image.LANCZOS)\n",
    "    transform = transforms.ToTensor()\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    return image_tensor\n",
    "\n",
    "def create_image_pyramid(image, num_scales, r=4/3):\n",
    "    image_pyramid = [image]\n",
    "    for _ in range(num_scales - 1):\n",
    "        h = image.shape[2]\n",
    "        w = image.shape[3]\n",
    "        new_size = (int(h / r), int(w / r))\n",
    "        image = torch.nn.functional.interpolate(image, size=new_size, mode=\"bilinear\", align_corners=False) \n",
    "        image_pyramid.append(image)\n",
    "    return image_pyramid\n",
    "\n",
    "def get_num_scales(image_size, min_dim=25, r=4/3):\n",
    "    max_dim = max(image_size)\n",
    "    num_scales = 0\n",
    "    dim = max_dim\n",
    "    while dim > min_dim:\n",
    "        dim = dim / r\n",
    "        num_scales += 1\n",
    "    return num_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_channels=3, n_kernels_per_block=32):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            self._conv_block(num_channels*2, n_kernels_per_block),\n",
    "            self._conv_block(n_kernels_per_block, n_kernels_per_block),\n",
    "            self._conv_block(n_kernels_per_block, n_kernels_per_block),\n",
    "            self._conv_block(n_kernels_per_block, n_kernels_per_block),\n",
    "            nn.Conv2d(n_kernels_per_block, num_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, upsampled_image):\n",
    "        input_tensor = torch.cat((noise, upsampled_image), dim=1)\n",
    "        residual_image = self.conv_blocks(input_tensor)\n",
    "        output_image = upsampled_image + residual_image\n",
    "        return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_channels=3, n_kernels_per_block=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            self._conv_block(num_channels, n_kernels_per_block),\n",
    "            self._conv_block(n_kernels_per_block, n_kernels_per_block),\n",
    "            self._conv_block(n_kernels_per_block, n_kernels_per_block),\n",
    "            self._conv_block(n_kernels_per_block, n_kernels_per_block),\n",
    "            nn.Conv2d(n_kernels_per_block, 1, kernel_size=3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_blocks(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def wgan_gp_loss(discriminator, real_images, generated_images, device, lambda_gp=10):\n",
    "    batch_size = real_images.shape[0]\n",
    "\n",
    "    real_scores = discriminator(real_images)\n",
    "    real_scores = real_scores.mean()\n",
    "\n",
    "    fake_scores = discriminator(generated_images)\n",
    "    fake_scores = fake_scores.mean()\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 9 scales\n",
      "Training scale: 9/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: Error detected in ConvolutionBackward0. Traceback of forward call that caused the error:\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Atharva\\AppData\\Local\\Temp\\ipykernel_14888\\2777757601.py\", line 18, in <module>\n",
      "    trained_generators = train_singan(image, num_scales, device)\n",
      "  File \"C:\\Users\\Atharva\\AppData\\Local\\Temp\\ipykernel_14888\\2160153662.py\", line 57, in train_singan\n",
      "    loss_d, loss_g = wgan_gp_loss(discriminators[n], image_pyramid[n], generated_image, device)\n",
      "  File \"C:\\Users\\Atharva\\AppData\\Local\\Temp\\ipykernel_14888\\891212083.py\", line 9, in wgan_gp_loss\n",
      "    fake_scores = discriminator(generated_images)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Atharva\\AppData\\Local\\Temp\\ipykernel_14888\\1560080325.py\", line 22, in forward\n",
      "    out = self.conv_blocks(x)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 457, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"c:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 453, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      " (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 128, 3, 3]] is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_scales\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m scales\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train SinGAN\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m trained_generators \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_singan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_scales\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#Generate sample using all scales\u001b[39;00m\n\u001b[0;32m     21\u001b[0m generated_image \u001b[38;5;241m=\u001b[39m generate_sample(trained_generators, device, num_scales, original_size\u001b[38;5;241m=\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]))\n",
      "Cell \u001b[1;32mIn[46], line 66\u001b[0m, in \u001b[0;36mtrain_singan\u001b[1;34m(image, num_scales, device, lr_gen, lr_disc, beta1, beta2, num_epochs, n_kernels_per_block, alpha_rec)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Train Generator\u001b[39;00m\n\u001b[0;32m     65\u001b[0m optimizers_g[n]\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 66\u001b[0m \u001b[43mloss_g\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m optimizers_g[n]\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Reconstruct image from fixed noise for Reconstruction Loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Atharva\\miniconda3\\envs\\singan\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 128, 3, 3]] is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
